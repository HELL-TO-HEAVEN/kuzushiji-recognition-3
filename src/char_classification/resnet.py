from __future__ import print_function
import keras
from keras.layers import Dense, Conv2D, BatchNormalization, Activation, LeakyReLU
from keras.layers import AveragePooling2D, GlobalAveragePooling2D, Input, Flatten, Add, Concatenate, Flatten
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2
from keras import backend as K
from keras.models import Model
from keras.models import load_model
from keras.utils import plot_model

import tensorflow as tf

import numpy as np
import os

from char_classification import data_operator
from kuzushiji_data import visualization as visu

class ResNet20:
    """
    https://keras.io/examples/cifar10_resnet/
    """
    def __init__(self, image_shape, num_class):
        # gray : (h, w, 1)
        self.IMAGE_SHAPE = image_shape
        self.NUM_CLASS = num_class

        return

    def build_model(self):
        self.model = self.resnet_v2(input_shape=self.IMAGE_SHAPE, depth=20, num_classes=self.NUM_CLASS)
        return

    def train_model(self, train_image, train_class, 
                    val_image, val_class, 
                    learning_rate, epochs, batch_size):

        # model compile
        self.model.compile(loss='categorical_crossentropy',
              optimizer=Adam(lr=learning_rate),
              metrics=['accuracy'])

        self.model.summary()

        # learning rate
        self.LEARNING_RATE = learning_rate
        lr_scheduler = LearningRateScheduler(self.lr_schedule)
        lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),
                                       cooldown=0,
                                       patience=5,
                                       min_lr=0.5e-6)
        callbacks = [lr_reducer, lr_scheduler]


        # This will do preprocessing and realtime data augmentation:
        datagen = ImageDataGenerator(
            # set input mean to 0 over the dataset
            featurewise_center=False,
            # set each sample mean to 0
            samplewise_center=False,
            # divide inputs by std of dataset
            featurewise_std_normalization=False,
            # divide each input by its std
            samplewise_std_normalization=False,
            # apply ZCA whitening
            zca_whitening=False,
            # epsilon for ZCA whitening
            zca_epsilon=1e-06,
            # randomly rotate images in the range (deg 0 to 180)
            rotation_range=0,
            # randomly shift images horizontally
            width_shift_range=0.1,
            # randomly shift images vertically
            height_shift_range=0.1,
            # set range for random shear
            shear_range=0.,
            # set range for random zoom
            zoom_range=0.2,
            # set range for random channel shifts
            channel_shift_range=0.,
            # set mode for filling points outside the input boundaries
            fill_mode='nearest',
            # value used for fill_mode = "constant"
            cval=0.,
            # randomly flip images
            horizontal_flip=False,
            # randomly flip images
            vertical_flip=False,
            # set rescaling factor (applied before any other transformation)
            rescale=None,
            # set function that will be applied on each input
            preprocessing_function=None,
            # image data format, either "channels_first" or "channels_last"
            data_format=None,
            # fraction of images reserved for validation (strictly between 0 and 1)
            validation_split=0.0)

        # Fit the model on the batches generated by datagen.flow().
        self.model.fit_generator(datagen.flow(train_image, train_class, batch_size=batch_size),
                                validation_data=(val_image, val_class),
                                epochs=epochs, steps_per_epoch=len(train_image)/batch_size,
                                callbacks=callbacks)

        return

    def lr_schedule(self, epoch):
        """Learning Rate Schedule

        Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.
        Called automatically every epoch as part of callbacks during training.

        # Arguments
            epoch (int): The number of epochs

        # Returns
            lr (float32): learning rate
        """
        lr = self.LEARNING_RATE
        if epoch > 180:
            lr *= 0.5e-3
        elif epoch > 160:
            lr *= 1e-3
        elif epoch > 120:
            lr *= 1e-2
        elif epoch > 80:
            lr *= 1e-1
        return lr

    def resnet_layer(self, inputs,
                 num_filters=16,
                 kernel_size=3,
                 strides=1,
                 activation='relu',
                 batch_normalization=True,
                 conv_first=True):
        """2D Convolution-Batch Normalization-Activation stack builder

        # Arguments
            inputs (tensor): input tensor from input image or previous layer
            num_filters (int): Conv2D number of filters
            kernel_size (int): Conv2D square kernel dimensions
            strides (int): Conv2D square stride dimensions
            activation (string): activation name
            batch_normalization (bool): whether to include batch normalization
            conv_first (bool): conv-bn-activation (True) or
                bn-activation-conv (False)

        # Returns
            x (tensor): tensor as input to the next layer
        """
        conv = Conv2D(num_filters,
                      kernel_size=kernel_size,
                      strides=strides,
                      padding='same',
                      kernel_initializer='he_normal',
                      kernel_regularizer=l2(1e-4))

        x = inputs
        if conv_first:
            x = conv(x)
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
        else:
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
            x = conv(x)
        return x

    def resnet_v2(self, input_shape, depth, num_classes):
        """ResNet Version 2 Model builder [b]

        Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as
        bottleneck layer
        First shortcut connection per layer is 1 x 1 Conv2D.
        Second and onwards shortcut connection is identity.
        At the beginning of each stage, the feature map size is halved (downsampled)
        by a convolutional layer with strides=2, while the number of filter maps is
        doubled. Within each stage, the layers have the same number filters and the
        same filter map sizes.
        Features maps sizes:
        conv1  : 32x32,  16
        stage 0: 32x32,  64
        stage 1: 16x16, 128
        stage 2:  8x8,  256

        # Arguments
            input_shape (tensor): shape of input image tensor
            depth (int): number of core convolutional layers
            num_classes (int): number of classes (CIFAR10 has 10)

        # Returns
            model (Model): Keras model instance
        """
        if (depth - 2) % 9 != 0:
            raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')
        # Start model definition.
        num_filters_in = 16
        num_res_blocks = int((depth - 2) / 9)

        inputs = Input(shape=input_shape)
        # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths
        x = self.resnet_layer(inputs=inputs,
                         num_filters=num_filters_in,
                         conv_first=True)

        # Instantiate the stack of residual units
        for stage in range(3):
            for res_block in range(num_res_blocks):
                activation = 'relu'
                batch_normalization = True
                strides = 1
                if stage == 0:
                    num_filters_out = num_filters_in * 4
                    if res_block == 0:  # first layer and first stage
                        activation = None
                        batch_normalization = False
                else:
                    num_filters_out = num_filters_in * 2
                    if res_block == 0:  # first layer but not first stage
                        strides = 2    # downsample

                # bottleneck residual unit
                y = self.resnet_layer(inputs=x,
                                 num_filters=num_filters_in,
                                 kernel_size=1,
                                 strides=strides,
                                 activation=activation,
                                 batch_normalization=batch_normalization,
                                 conv_first=False)
                y = self.resnet_layer(inputs=y,
                                 num_filters=num_filters_in,
                                 conv_first=False)
                y = self.resnet_layer(inputs=y,
                                 num_filters=num_filters_out,
                                 kernel_size=1,
                                 conv_first=False)
                if res_block == 0:
                    # linear projection residual shortcut connection to match
                    # changed dims
                    x = self.resnet_layer(inputs=x,
                                     num_filters=num_filters_out,
                                     kernel_size=1,
                                     strides=strides,
                                     activation=None,
                                     batch_normalization=False)
                x = keras.layers.add([x, y])

            num_filters_in = num_filters_out

        # Add classifier on top.
        # v2 has BN-ReLU before Pooling
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = AveragePooling2D(pool_size=8)(x)
        y = Flatten()(x)
        outputs = Dense(num_classes,
                        activation='softmax',
                        kernel_initializer='he_normal')(y)

        # Instantiate model.
        model = Model(inputs=inputs, outputs=outputs)
        return model
    
    def save_model(self, save_file, only_model_plot=False):
        """
        save model
        """
        # make dir
        save_dir = os.path.dirname(save_file)
        if not os.path.isdir(save_dir):
            os.makedirs(save_dir)

        # visualize
        plot_model(self.model, to_file=os.path.join(save_dir, 'model_structure.png'), show_shapes=True, show_layer_names=False)

        if not only_model_plot:
            # save model
            self.model.save(save_file)
            print('Saved trained model at %s ' % save_file)

        return

    def load_model(self, model_file):
        """
        load model .h5 file
        """
        self.model = load_model(model_file)
        return

    def predict(self, images):
        oups = self.model.predict(images)
        oup_numbers = np.argmax(oups, axis=1)

        return oup_numbers

    def predict_tta(self, images, aug_num,
                    rotation_range=0, 
                    width_shift_range=0.1, height_shift_range=0.1, 
                    zoom_range=0.2, 
                    horizontal_flip=False, vertical_flip=False,):
        """
        test time augmentation
        http://ultraist.hatenablog.com/entry/2015/03/20/121031
        """
        if aug_num < 1:
            oup_numbers = self.predict(images)
        else:
            datagen = ImageDataGenerator(
                # set input mean to 0 over the dataset
                featurewise_center=False,
                # set each sample mean to 0
                samplewise_center=False,
                # divide inputs by std of dataset
                featurewise_std_normalization=False,
                # divide each input by its std
                samplewise_std_normalization=False,
                # apply ZCA whitening
                zca_whitening=False,
                # epsilon for ZCA whitening
                zca_epsilon=1e-06,
                # randomly rotate images in the range (deg 0 to 180)
                rotation_range=rotation_range,
                # randomly shift images horizontally
                width_shift_range=width_shift_range,
                # randomly shift images vertically
                height_shift_range=height_shift_range,
                # set range for random shear
                shear_range=0.,
                # set range for random zoom
                zoom_range=zoom_range,
                # set range for random channel shifts
                channel_shift_range=0.,
                # set mode for filling points outside the input boundaries
                fill_mode='nearest',
                # value used for fill_mode = "constant"
                cval=0.,
                # randomly flip images
                horizontal_flip=horizontal_flip,
                # randomly flip images
                vertical_flip=vertical_flip,
                # set rescaling factor (applied before any other transformation)
                rescale=None,
                # set function that will be applied on each input
                preprocessing_function=None,
                # image data format, either "channels_first" or "channels_last"
                data_format=None,
                # fraction of images reserved for validation (strictly between 0 and 1)
                validation_split=0.0)
        
            # batch size. data num is 1 or not.
            batch_size = len(images) if len(images.shape) == 4 else 1
            gen = datagen.flow(images, batch_size=batch_size, shuffle=False)

            # tta
            oups = self.model.predict(images)
            for i in range(aug_num):
                aug_images = next(gen)
                aug_oups = self.model.predict(aug_images)
                oups = oups + aug_oups
            oups = oups / (aug_num + 1)

            # output number
            oup_numbers = np.argmax(oups, axis=1)

        return oup_numbers

    def predict_tta2(self, images, tta_func):
        """
        Args:
            tta_func:  tta_func(images): return augmented images set. image set is [aug image1, ..., aug imageN].
        """
        auged_imgs_set = tta_func(images)
        aug_num = len(auged_imgs_set)

        for iaug, auged_imgs in enumerate(auged_imgs_set):
            if iaug == 0:
                oups = self.model.predict(auged_imgs)
            else:
                oups = oups + self.model.predict(auged_imgs)

        oups = oups / aug_num
        # output number
        oup_numbers = np.argmax(oups, axis=1)
        
        return oup_numbers

class ResNet:
    """
    https://keras.io/examples/cifar10_resnet/
    """
    def __init__(self, image_shape, num_class, resnet_version):
        # gray : (h, w, 1)
        self.IMAGE_SHAPE = image_shape
        self.NUM_CLASS = num_class

        self.RESNET_VERSION = resnet_version

        return

    def build_model(self):
        if self.RESNET_VERSION == 'ver1':
            self.model = self.resnet_ver1(input_shape=self.IMAGE_SHAPE, num_classes=self.NUM_CLASS)
        elif self.RESNET_VERSION == 'ver2':
            self.model = self.resnet_ver2(input_shape=self.IMAGE_SHAPE, num_classes=self.NUM_CLASS)
        
        return

    def train_model(self, train_x, train_y, 
                    val_x, val_y, 
                    learning_rate, epochs, batch_size, 
                    save_file=None, csv_file=None):

        # model compile
        self.model.compile(loss='categorical_crossentropy',
              optimizer=Adam(lr=learning_rate),
              metrics=['accuracy'])
        self.model.summary()

        # call back
        callbacks = []

        # learning rate
        self.LEARNING_RATE = learning_rate
        lr_scheduler = LearningRateScheduler(self.lr_schedule)
        #lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),
        #                               cooldown=0,
        #                               patience=5,
        #                               min_lr=0.5e-6)
        #callbacks = [lr_reducer, lr_scheduler]
        callbacks.append(lr_scheduler)
        
        # save model
        if save_file is not None:
            checkpoint = ModelCheckpoint(filepath=save_file,
                                         monitor='val_acc',
                                         verbose=1,
                                         save_best_only=True)
            callbacks.append(checkpoint)
        # save csv
        if csv_file is not None:
            csvlogger = CSVLogger(csv_file)
            callbacks.append(csvlogger)

        # This will do preprocessing and realtime data augmentation:
        datagen = ImageDataGenerator(
            # set input mean to 0 over the dataset
            featurewise_center=False,
            # set each sample mean to 0
            samplewise_center=False,
            # divide inputs by std of dataset
            featurewise_std_normalization=False,
            # divide each input by its std
            samplewise_std_normalization=False,
            # apply ZCA whitening
            zca_whitening=False,
            # epsilon for ZCA whitening
            zca_epsilon=1e-06,
            # randomly rotate images in the range (deg 0 to 180)
            rotation_range=0,
            # randomly shift images horizontally
            width_shift_range=0.1,
            # randomly shift images vertically
            height_shift_range=0.1,
            # set range for random shear
            shear_range=0.,
            # set range for random zoom
            zoom_range=0.2,
            # set range for random channel shifts
            channel_shift_range=0.,
            # set mode for filling points outside the input boundaries
            fill_mode='nearest',
            # value used for fill_mode = "constant"
            cval=0.,
            # randomly flip images
            horizontal_flip=False,
            # randomly flip images
            vertical_flip=False,
            # set rescaling factor (applied before any other transformation)
            rescale=None,
            # set function that will be applied on each input
            preprocessing_function=None,
            # image data format, either "channels_first" or "channels_last"
            data_format=None,
            # fraction of images reserved for validation (strictly between 0 and 1)
            validation_split=0.0)

        # Fit the model on the batches generated by datagen.flow().
        self.model.fit_generator(datagen.flow(train_x, train_y, batch_size=batch_size),
                                validation_data=(val_x, val_y),
                                epochs=epochs, steps_per_epoch=len(train_x)/batch_size,
                                callbacks=callbacks)

        return

    def lr_schedule(self, epoch):
        """Learning Rate Schedule

        Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.
        Called automatically every epoch as part of callbacks during training.

        # Arguments
            epoch (int): The number of epochs

        # Returns
            lr (float32): learning rate
        """
        lr = self.LEARNING_RATE
        if epoch > 180:
            lr *= 0.5e-3
        elif epoch > 160:
            lr *= 1e-3
        elif epoch > 120:
            lr *= 1e-2
        elif epoch > 80:
            lr *= 1e-1
        return lr

    def resnet_layer(self, inputs,
                 num_filters=16,
                 kernel_size=3,
                 strides=1,
                 activation='relu',
                 batch_normalization=True,
                 conv_first=True):
        """2D Convolution-Batch Normalization-Activation stack builder

        # Arguments
            inputs (tensor): input tensor from input image or previous layer
            num_filters (int): Conv2D number of filters
            kernel_size (int): Conv2D square kernel dimensions
            strides (int): Conv2D square stride dimensions
            activation (string): activation name
            batch_normalization (bool): whether to include batch normalization
            conv_first (bool): conv-bn-activation (True) or
                bn-activation-conv (False)

        # Returns
            x (tensor): tensor as input to the next layer
        """
        conv = Conv2D(num_filters,
                      kernel_size=kernel_size,
                      strides=strides,
                      padding='same',
                      kernel_initializer='he_normal',
                      kernel_regularizer=l2(1e-4))

        x = inputs
        if conv_first:
            x = conv(x)
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
        else:
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
            x = conv(x)
        return x

    def resblock_ver1(self, input, num_block, num_filters, kernel_size, first_block_stride):
        """
        architecture: inp -> (conv -> bn -> relu), [kernel_size*kernel_size, num_filters], stride=first_block_stride
                          -> (conv -> bn -> relu)  [kernel_size*kernel_size, num_filters], stride=1
                          -> ... 
                          -> (conv -> bn)          [kernel_size*kernel_size, num_filters], stride=1
                          -> oup

        """
        x = input

        for iblock in range(num_block):
            # set stride
            if iblock == 0:
                stride = first_block_stride
            else:
                stride = 1

            # set activation
            if iblock != num_block - 1:
                activation = 'relu'
            else:
                activation = None

            # resnet layer
            x = self.resnet_layer(inputs=x,
                                  num_filters=num_filters,
                                  kernel_size=kernel_size,
                                  strides=stride,
                                  activation=activation,
                                  batch_normalization=True,
                                  conv_first=True)
        return x

    def resblock_ver2(self, input, num_block, num_filters, kernel_size, first_block_stride):
        """
        architecture: inp -> (conv -> bn -> relu), [kernel_size*kernel_size, num_filters], stride=first_block_stride
                          -> (conv -> bn -> relu)  [kernel_size*kernel_size, num_filters], stride=1
                          -> ... 
                          -> (conv -> bn)          [kernel_size*kernel_size, num_filters], stride=1
                          -> oup

        """
        x = input

        for iblock in range(num_block):
            # set stride
            if iblock == 0:
                stride = first_block_stride
            else:
                stride = 1

            # set activation
            if iblock != num_block - 1:
                activation = 'relu'
            else:
                activation = 'relu'

            # resnet layer
            x = self.resnet_layer(inputs=x,
                                  num_filters=num_filters,
                                  kernel_size=kernel_size,
                                  strides=stride,
                                  activation=activation,
                                  batch_normalization=True,
                                  conv_first=True)
        return x

    def shortcut(self, x, residual):
        '''
        http://pynote.hatenablog.com/entry/keras-resnet-implementation
        shortcut connection を作成する。
        '''
        x_shape = K.int_shape(x)
        residual_shape = K.int_shape(residual)

        if x_shape == residual_shape:
            # x と residual の形状が同じ場合、なにもしない。
            shortcut = x
        else:
            # x と residual の形状が異なる場合、線形変換を行い、形状を一致させる。
            stride_w = int(round(x_shape[1] / residual_shape[1]))
            stride_h = int(round(x_shape[2] / residual_shape[2]))

            shortcut = Conv2D(filters=residual_shape[3],
                              kernel_size=(1, 1),
                              strides=(stride_w, stride_h),
                              kernel_initializer='he_normal',
                              kernel_regularizer=l2(1.e-4))(x)
        return Add()([shortcut, residual])

    def resnet_ver1(self, input_shape, num_classes):
        FIRST_NUM_FILTER = 32
        FRIST_STRIDE = 2
        
        NUM_RES_BLOCK = [2, 2, 2]
        FIRST_BLOCK_STRIDES = [2, 2, 2]
        NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*8]

        # input
        image_inputs = Input(shape=input_shape)

        # first layer
        x = self.resnet_layer(inputs=image_inputs,
                              num_filters=FIRST_NUM_FILTER,
                              kernel_size=FRIST_STRIDE,
                              strides=1,
                              activation='relu',
                              batch_normalization=True,
                              conv_first=True)

        # stacked layer
        for istack in range(len(NUM_RES_BLOCK)):
            # res block
            y = self.resblock_ver1(input=x, 
                                   num_block=NUM_RES_BLOCK[istack], 
                                   num_filters=NUM_FILTERS[istack], 
                                   kernel_size=3, 
                                   first_block_stride=FIRST_BLOCK_STRIDES[istack])
            # shortcut
            x = self.shortcut(x, y)

        # to last layer
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = GlobalAveragePooling2D()(x)

        # classification
        outputs = Dense(num_classes,
                        activation='softmax',
                        kernel_initializer='he_normal')(x)

        # Instantiate model.
        model = Model(inputs=image_inputs, outputs=outputs)
        return model

    def resnet_ver2(self, input_shape, num_classes):
        FIRST_NUM_FILTER = 48
        FRIST_STRIDE = 2
        
        NUM_RES_BLOCK = [2, 2, 2]
        FIRST_BLOCK_STRIDES = [2, 2, 2]
        NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*8]

        # input
        image_inputs = Input(shape=input_shape)

        # first layer
        x = self.resnet_layer(inputs=image_inputs,
                              num_filters=FIRST_NUM_FILTER,
                              kernel_size=3,
                              strides=FRIST_STRIDE,
                              activation='relu',
                              batch_normalization=True,
                              conv_first=True)

        # stacked layer
        for istack in range(len(NUM_RES_BLOCK)):
            # res block
            y = self.resblock_ver1(input=x, 
                                   num_block=NUM_RES_BLOCK[istack], 
                                   num_filters=NUM_FILTERS[istack], 
                                   kernel_size=3, 
                                   first_block_stride=FIRST_BLOCK_STRIDES[istack])
            # shortcut
            x = self.shortcut(x, y)

        # to last layer
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = GlobalAveragePooling2D()(x)

        # classification
        outputs = Dense(num_classes,
                        activation='softmax',
                        kernel_initializer='he_normal')(x)

        # Instantiate model.
        model = Model(inputs=image_inputs, outputs=outputs)
        return model

    def save_model(self, save_file, only_model_plot=False):
        """
        save model
        """
        # make dir
        save_dir = os.path.dirname(save_file)
        if not os.path.isdir(save_dir):
            os.makedirs(save_dir)

        # visualize
        plot_model(self.model, to_file=os.path.join(save_dir, 'model_structure.png'), show_shapes=True, show_layer_names=False)

        if not only_model_plot:
            # save model
            self.model.save(save_file)
            print('Saved trained model at %s ' % save_file)

        return

    def load_model(self, model_file):
        """
        load model .h5 file
        """
        self.model = load_model(model_file)
        return

    def predict(self, images):
        oups = self.model.predict(images)
        oup_numbers = np.argmax(oups, axis=1)

        return oup_numbers

    def predict_tta(self, images, aug_num,
                    rotation_range=0, 
                    width_shift_range=0.1, height_shift_range=0.1, 
                    zoom_range=0.2, 
                    horizontal_flip=False, vertical_flip=False,):
        """
        test time augmentation
        http://ultraist.hatenablog.com/entry/2015/03/20/121031
        """
        if aug_num < 1:
            oup_numbers = self.predict(images)
        else:
            datagen = ImageDataGenerator(
                # set input mean to 0 over the dataset
                featurewise_center=False,
                # set each sample mean to 0
                samplewise_center=False,
                # divide inputs by std of dataset
                featurewise_std_normalization=False,
                # divide each input by its std
                samplewise_std_normalization=False,
                # apply ZCA whitening
                zca_whitening=False,
                # epsilon for ZCA whitening
                zca_epsilon=1e-06,
                # randomly rotate images in the range (deg 0 to 180)
                rotation_range=rotation_range,
                # randomly shift images horizontally
                width_shift_range=width_shift_range,
                # randomly shift images vertically
                height_shift_range=height_shift_range,
                # set range for random shear
                shear_range=0.,
                # set range for random zoom
                zoom_range=zoom_range,
                # set range for random channel shifts
                channel_shift_range=0.,
                # set mode for filling points outside the input boundaries
                fill_mode='nearest',
                # value used for fill_mode = "constant"
                cval=0.,
                # randomly flip images
                horizontal_flip=horizontal_flip,
                # randomly flip images
                vertical_flip=vertical_flip,
                # set rescaling factor (applied before any other transformation)
                rescale=None,
                # set function that will be applied on each input
                preprocessing_function=None,
                # image data format, either "channels_first" or "channels_last"
                data_format=None,
                # fraction of images reserved for validation (strictly between 0 and 1)
                validation_split=0.0)
        
            # batch size. data num is 1 or not.
            batch_size = len(images) if len(images.shape) == 4 else 1
            gen = datagen.flow(images, batch_size=batch_size, shuffle=False)

            # tta
            oups = self.model.predict(images)
            for i in range(aug_num):
                aug_images = next(gen)
                aug_oups = self.model.predict(aug_images)
                oups = oups + aug_oups
            oups = oups / (aug_num + 1)

            # output number
            oup_numbers = np.argmax(oups, axis=1)

        return oup_numbers

    def predict_tta2(self, images, tta_func):
        """
        Args:
            tta_func:  tta_func(images): return augmented images set. image set is [aug image1, ..., aug imageN].
        """
        auged_imgs_set = tta_func(images)
        aug_num = len(auged_imgs_set)

        for iaug, auged_imgs in enumerate(auged_imgs_set):
            if iaug == 0:
                oups = self.model.predict(auged_imgs)
            else:
                oups = oups + self.model.predict(auged_imgs)

        oups = oups / aug_num
        # output number
        oup_numbers = np.argmax(oups, axis=1)
        
        return oup_numbers

class ResNet_with_otherinput:
    """
    https://keras.io/examples/cifar10_resnet/
    """
    def __init__(self, image_shape, num_class, resnet_version, other_input_shape):
        # gray : (h, w, 1)
        self.IMAGE_SHAPE = image_shape
        self.NUM_CLASS = num_class

        self.RESNET_VERSION = resnet_version

        self.OTHER_INPUT_SHAPE = other_input_shape

        self.train_hist = None

        return

    def build_model(self):
        if self.RESNET_VERSION == 'ver1':
            self.model = self.resnet_ver1(input_shape=self.IMAGE_SHAPE, 
                                          other_input_shape=self.OTHER_INPUT_SHAPE, 
                                          num_classes=self.NUM_CLASS)
        return

    def train_model(self, train_x, train_y, 
                    val_x, val_y, 
                    learning_rate, epochs, batch_size, 
                    save_file=None, csv_file=None):

        # model compile
        self.model.compile(loss='categorical_crossentropy',
              optimizer=Adam(lr=learning_rate),
              metrics=['accuracy'])
        self.model.summary()

        # call back
        callbacks = []

        # learning rate
        self.LEARNING_RATE = learning_rate
        lr_scheduler = LearningRateScheduler(self.lr_schedule)
        #lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),
        #                               cooldown=0,
        #                               patience=5,
        #                               min_lr=0.5e-6)
        #callbacks = [lr_reducer, lr_scheduler]
        callbacks.append(lr_scheduler)
        
        # save model
        if save_file is not None:
            checkpoint = ModelCheckpoint(filepath=save_file,
                                         monitor='val_acc',
                                         verbose=1,
                                         save_best_only=True)
            callbacks.append(checkpoint)
        # save csv
        if csv_file is not None:
            csvlogger = CSVLogger(csv_file)
            callbacks.append(csvlogger)

        # This will do preprocessing and realtime data augmentation:
        image_gen_args = {
            # set input mean to 0 over the dataset
            "featurewise_center":False,
            # set each sample mean to 0
            "samplewise_center":False,
            # divide inputs by std of dataset
            "featurewise_std_normalization":False,
            # divide each input by its std
            "samplewise_std_normalization":False,
            # apply ZCA whitening
            "zca_whitening":False,
            # epsilon for ZCA whitening
            "zca_epsilon":1e-06,
            # randomly rotate images in the range (deg 0 to 180)
            "rotation_range":0,
            # randomly shift images horizontally
            "width_shift_range":0.1,
            # randomly shift images vertically
            "height_shift_range":0.1,
            # set range for random shear
            "shear_range":0.,
            # set range for random zoom
            "zoom_range":0.2,
            # set range for random channel shifts
            "channel_shift_range":0.,
            # set mode for filling points outside the input boundaries
            "fill_mode":'nearest',
            # value used for fill_mode : "constant"
            "cval":0.,
            # randomly flip images
            "horizontal_flip":False,
            # randomly flip images
            "vertical_flip":False,
            # set rescaling factor (applied before any other transformation)
            "rescale":None,
            # set function that will be applied on each input
            "preprocessing_function":None,
            # image data format, either "channels_first" or "channels_last"
            "data_format":None,
            # fraction of images reserved for validation (strictly between 0 and 1)
            "validation_split":0.0}

        datagen = data_operator.ImageDataGeneratorWithOtherInputs(
                    images=train_x[0], 
                    other_inputs=train_x[1], 
                    y=train_y, 
                    batch_size=batch_size, 
                    image_generator_args=image_gen_args)

        # Fit the model on the batches generated by datagen.flow().
        self.train_hist = self.model.fit_generator(datagen,
                                validation_data=(val_x, val_y),
                                epochs=epochs, 
                                steps_per_epoch=len(train_x[0])/batch_size,
                                callbacks=callbacks, 
                                )

        return

    def lr_schedule(self, epoch):
        """Learning Rate Schedule

        Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.
        Called automatically every epoch as part of callbacks during training.

        # Arguments
            epoch (int): The number of epochs

        # Returns
            lr (float32): learning rate
        """
        lr = self.LEARNING_RATE
        if epoch > 180:
            lr *= 0.5e-3
        elif epoch > 160:
            lr *= 1e-3
        elif epoch > 120:
            lr *= 1e-2
        elif epoch > 80:
            lr *= 1e-1
        return lr

    def resnet_layer(self, inputs,
                 num_filters=16,
                 kernel_size=3,
                 strides=1,
                 activation='relu',
                 batch_normalization=True,
                 conv_first=True):
        """2D Convolution-Batch Normalization-Activation stack builder

        # Arguments
            inputs (tensor): input tensor from input image or previous layer
            num_filters (int): Conv2D number of filters
            kernel_size (int): Conv2D square kernel dimensions
            strides (int): Conv2D square stride dimensions
            activation (string): activation name
            batch_normalization (bool): whether to include batch normalization
            conv_first (bool): conv-bn-activation (True) or
                bn-activation-conv (False)

        # Returns
            x (tensor): tensor as input to the next layer
        """
        conv = Conv2D(num_filters,
                      kernel_size=kernel_size,
                      strides=strides,
                      padding='same',
                      kernel_initializer='he_normal',
                      kernel_regularizer=l2(1e-4))

        x = inputs
        if conv_first:
            x = conv(x)
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
        else:
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
            x = conv(x)
        return x

    def resblock_ver1(self, input, num_block, num_filters, kernel_size, first_block_stride):
        """
        architecture: inp -> (conv -> bn -> relu), [kernel_size*kernel_size, num_filters], stride=first_block_stride
                          -> (conv -> bn -> relu)  [kernel_size*kernel_size, num_filters], stride=1
                          -> ... 
                          -> (conv -> bn)          [kernel_size*kernel_size, num_filters], stride=1
                          -> oup

        """
        x = input

        for iblock in range(num_block):
            # set stride
            if iblock == 0:
                stride = first_block_stride
            else:
                stride = 1

            # set activation
            if iblock != num_block - 1:
                activation = 'relu'
            else:
                activation = None

            # resnet layer
            x = self.resnet_layer(inputs=x,
                                  num_filters=num_filters,
                                  kernel_size=kernel_size,
                                  strides=stride,
                                  activation=activation,
                                  batch_normalization=True,
                                  conv_first=True)
        return x

    def shortcut(self, x, residual):
        '''
        http://pynote.hatenablog.com/entry/keras-resnet-implementation
        shortcut connection を作成する。
        '''
        x_shape = K.int_shape(x)
        residual_shape = K.int_shape(residual)

        if x_shape == residual_shape:
            # x と residual の形状が同じ場合、なにもしない。
            shortcut = x
        else:
            # x と residual の形状が異なる場合、線形変換を行い、形状を一致させる。
            stride_w = int(round(x_shape[1] / residual_shape[1]))
            stride_h = int(round(x_shape[2] / residual_shape[2]))

            shortcut = Conv2D(filters=residual_shape[3],
                              kernel_size=(1, 1),
                              strides=(stride_w, stride_h),
                              kernel_initializer='he_normal',
                              kernel_regularizer=l2(1.e-4))(x)
        return Add()([shortcut, residual])

    def resnet_ver1(self, input_shape, other_input_shape, num_classes):
        FIRST_NUM_FILTER = 48
        FRIST_STRIDE = 2
        
        NUM_RES_BLOCK = [2, 2, 2]
        FIRST_BLOCK_STRIDES = [2, 2, 2]
        NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*8]

        # input
        image_inputs = Input(shape=input_shape)

        # first layer
        x = self.resnet_layer(inputs=image_inputs,
                              num_filters=FIRST_NUM_FILTER,
                              kernel_size=3,
                              strides=FRIST_STRIDE,
                              activation='relu',
                              batch_normalization=True,
                              conv_first=True)

        # stacked layer
        for istack in range(len(NUM_RES_BLOCK)):
            # res block
            y = self.resblock_ver1(input=x, 
                                   num_block=NUM_RES_BLOCK[istack], 
                                   num_filters=NUM_FILTERS[istack], 
                                   kernel_size=3, 
                                   first_block_stride=FIRST_BLOCK_STRIDES[istack])
            # shortcut
            x = self.shortcut(x, y)

        # to last layer
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = GlobalAveragePooling2D()(x)
        x_shape = K.int_shape(x)

        # other inputs
        other_inputs = Input(shape=other_input_shape)
        z = other_inputs
        z = BatchNormalization()(z)
        #z = Flatten()(z)
        z_shape = K.int_shape(z)

        # concatenate
        x = Concatenate()([x, z])

        # fully conection
        #x = Dense(x_shape[1] + z_shape[1],
        #          activation='linear',
        #          kernel_initializer='he_normal')(x)
        #x = BatchNormalization()(x)
        #x = Activation('relu')(x)
        #x = LeakyReLU()(x)
        
        # classification
        outputs = Dense(num_classes,
                        activation='softmax',
                        kernel_initializer='he_normal')(x)

        # Instantiate model.
        model = Model(inputs=[image_inputs, other_inputs], outputs=outputs)
        return model

    def save_model(self, save_file, only_model_plot=False):
        """
        save model
        """
        # make dir
        save_dir = os.path.dirname(save_file)
        if not os.path.isdir(save_dir):
            os.makedirs(save_dir)

        # visualize
        plot_model(self.model, to_file=os.path.join(save_dir, 'model_structure.png'), show_shapes=True, show_layer_names=False)

        if not only_model_plot:
            # save model
            self.model.save(save_file)
            print('Saved trained model at %s ' % save_file)

        return

    def load_model(self, model_file):
        """
        load model .h5 file
        """
        self.model = load_model(model_file)
        return

    def predict(self, images):
        oups = self.model.predict(images)
        oup_numbers = np.argmax(oups, axis=1)

        return oup_numbers

    def predict_tta2(self, images, other_inputs, tta_func):
        """
        Args:
            tta_func:  tta_func(images): return augmented images set. image set is [aug image1, ..., aug imageN].
        """
        auged_imgs_set = tta_func(images)
        aug_num = len(auged_imgs_set)

        for iaug, auged_imgs in enumerate(auged_imgs_set):
            if iaug == 0:
                oups = self.model.predict([auged_imgs, other_inputs])
            else:
                oups = oups + self.model.predict([auged_imgs, other_inputs])

        oups = oups / aug_num
        # output number
        oup_numbers = np.argmax(oups, axis=1)
        
        return oup_numbers

class MyResNet:
    """
    https://arxiv.org/abs/1512.03385
    https://keras.io/examples/cifar10_resnet/
    """
    def __init__(self, image_shape, num_class, resnet_version, other_input_shape=None):
        # gray : (h, w, 1)
        self.IMAGE_SHAPE = image_shape
        self.NUM_CLASS = num_class

        self.RESNET_VERSION = resnet_version

        self.OTHER_INPUT_SHAPE = other_input_shape

        self.train_hist = None

        return

    def build_model(self):
        if self.RESNET_VERSION == 'ver1':
            self.model = self.resnet_ver1(input_shape=self.IMAGE_SHAPE, 
                                          other_input_shape=self.OTHER_INPUT_SHAPE, 
                                          num_classes=self.NUM_CLASS)
        elif self.RESNET_VERSION == 'ver2':
            self.model = self.resnet_ver2(input_shape=self.IMAGE_SHAPE, 
                                          other_input_shape=self.OTHER_INPUT_SHAPE, 
                                          num_classes=self.NUM_CLASS)
        elif self.RESNET_VERSION == 'ver3':
            self.model = self.resnet_ver3(input_shape=self.IMAGE_SHAPE, 
                                          other_input_shape=self.OTHER_INPUT_SHAPE, 
                                          num_classes=self.NUM_CLASS)

        return

    def train_model(self, train_x, train_y, 
                    val_x, val_y, 
                    learning_rate, epochs, batch_size, 
                    class_balance_loss_effective_beta=None,
                    focal_loss_gamma=None,
                    random_erasing_kwargs=None, 
                    mixup_alpha=None,
                    normalize_by_1275=False,
                    save_file=None, csv_file=None):

        # model compile
        if (class_balance_loss_effective_beta is None) and (focal_loss_gamma is None):
            # categorical crossentropy
            self.model.compile(loss='categorical_crossentropy',
                  optimizer=Adam(lr=learning_rate),
                  metrics=['accuracy'])
        else:
            # constant
            self.CLASS_BALANCE_LOSS_EFFECTIVE_BETA = class_balance_loss_effective_beta
            self.FOCAL_LOSS_GAMMA = focal_loss_gamma
            self.TRUE_EACH_LABEL_NUM = np.sum(train_y, axis=0)
            # class balanced loss, focal loss
            self.model.compile(loss=self.__class_balanced_focal_loss,
                  optimizer=Adam(lr=learning_rate),
                  metrics=['accuracy'])

        # summary
        self.model.summary()

        # call back
        callbacks = []

        # learning rate
        self.LEARNING_RATE = learning_rate
        lr_scheduler = LearningRateScheduler(self.__lr_schedule)
        #lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),
        #                               cooldown=0,
        #                               patience=5,
        #                               min_lr=0.5e-6)
        #callbacks = [lr_reducer, lr_scheduler]
        callbacks.append(lr_scheduler)
        
        # save model
        if save_file is not None:
            checkpoint = ModelCheckpoint(filepath=save_file,
                                         monitor='val_acc',
                                         verbose=1,
                                         save_best_only=True)
            callbacks.append(checkpoint)
        # save csv
        if csv_file is not None:
            csvlogger = CSVLogger(csv_file)
            callbacks.append(csvlogger)

        # This will do preprocessing and realtime data augmentation:
        image_gen_args = {
            # set input mean to 0 over the dataset
            "featurewise_center":False,
            # set each sample mean to 0
            "samplewise_center":False,
            # divide inputs by std of dataset
            "featurewise_std_normalization":False,
            # divide each input by its std
            "samplewise_std_normalization":False,
            # apply ZCA whitening
            "zca_whitening":False,
            # epsilon for ZCA whitening
            "zca_epsilon":1e-06,
            # randomly rotate images in the range (deg 0 to 180)
            "rotation_range":5,
            # randomly shift images horizontally
            "width_shift_range":0.1,
            # randomly shift images vertically
            "height_shift_range":0.1,
            # set range for random shear
            "shear_range":0.,
            # set range for random zoom
            "zoom_range":0.2,
            # set range for random channel shifts
            "channel_shift_range":0.,
            # set mode for filling points outside the input boundaries
            "fill_mode":'nearest',
            # value used for fill_mode : "constant"
            "cval":0.,
            # randomly flip images
            "horizontal_flip":False,
            # randomly flip images
            "vertical_flip":False,
            # set rescaling factor (applied before any other transformation)
            "rescale":None,
            # set function that will be applied on each input
            "preprocessing_function":None,
            # image data format, either "channels_first" or "channels_last"
            "data_format":None,
            # fraction of images reserved for validation (strictly between 0 and 1)
            "validation_split":0.0}

        if self.OTHER_INPUT_SHAPE is None:
            datagen = ImageDataGenerator(**image_gen_args).flow(train_x, train_y, batch_size=batch_size)
        else:
            datagen = data_operator.ImageDataGeneratorWithOtherInputs(
                        images=train_x[0], 
                        other_inputs=train_x[1], 
                        y=train_y, 
                        batch_size=batch_size, 
                        image_generator_args=image_gen_args,
                        random_erasing_kwargs=random_erasing_kwargs,
                        mixup_alpha=mixup_alpha,
                        normalize_by_1275=normalize_by_1275)
            val_datagen = data_operator.ImageDataGeneratorWithOtherInputs(
                        images=val_x[0], 
                        other_inputs=val_x[1], 
                        y=val_y, 
                        batch_size=batch_size, 
                        image_generator_args=None,
                        random_erasing_kwargs=None,
                        mixup_alpha=None,
                        normalize_by_1275=normalize_by_1275)

        #xxx = datagen[0]

        # Fit the model on the batches generated by datagen.flow().
        if self.OTHER_INPUT_SHAPE is None:
            self.train_hist = self.model.fit_generator(datagen,
                                    validation_data=(val_x, val_y),
                                    epochs=epochs, 
                                    steps_per_epoch=len(train_x[0])/batch_size,
                                    callbacks=callbacks, 
                                    )
        else:
            self.train_hist = self.model.fit_generator(datagen,
                                    validation_data=val_datagen,
                                    epochs=epochs, 
                                    steps_per_epoch=len(train_x[0])/batch_size,
                                    callbacks=callbacks, 
                                    )

        return

    def __lr_schedule(self, epoch):
        """Learning Rate Schedule

        Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.
        Called automatically every epoch as part of callbacks during training.

        # Arguments
            epoch (int): The number of epochs

        # Returns
            lr (float32): learning rate
        """
        lr = self.LEARNING_RATE
        if epoch > 180:
            lr *= 0.5e-3
        elif epoch > 160:
            lr *= 1e-3
        elif epoch > 120:
            lr *= 1e-2
        elif epoch > 80:
            lr *= 1e-1
        return lr

    def __resnet_layer(self, inputs,
                 num_filters=16,
                 kernel_size=3,
                 strides=1,
                 activation='relu',
                 batch_normalization=True,
                 conv_first=True):
        """2D Convolution-Batch Normalization-Activation stack builder

        # Arguments
            inputs (tensor): input tensor from input image or previous layer
            num_filters (int): Conv2D number of filters
            kernel_size (int): Conv2D square kernel dimensions
            strides (int): Conv2D square stride dimensions
            activation (string): activation name
            batch_normalization (bool): whether to include batch normalization
            conv_first (bool): conv-bn-activation (True) or
                bn-activation-conv (False)

        # Returns
            x (tensor): tensor as input to the next layer
        """
        conv = Conv2D(num_filters,
                      kernel_size=kernel_size,
                      strides=strides,
                      padding='same',
                      kernel_initializer='he_normal',
                      kernel_regularizer=l2(1e-4))

        x = inputs
        if conv_first:
            x = conv(x)
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
        else:
            if batch_normalization:
                x = BatchNormalization()(x)
            if activation is not None:
                x = Activation(activation)(x)
            x = conv(x)
        return x

    def __resblock_ver1(self, input, num_block, num_filters, kernel_size, first_block_stride):
        """
        architecture: inp -> (conv -> bn -> relu), [kernel_size*kernel_size, num_filters], stride=first_block_stride
                          -> (conv -> bn -> relu)  [kernel_size*kernel_size, num_filters], stride=1
                          -> ... 
                          -> (conv -> bn)          [kernel_size*kernel_size, num_filters], stride=1
                          -> oup

        """
        x = input

        for iblock in range(num_block):
            # set stride
            if iblock == 0:
                stride = first_block_stride
            else:
                stride = 1

            # set activation
            if iblock != num_block - 1:
                activation = 'relu'
            else:
                activation = None

            # resnet layer
            x = self.__resnet_layer(inputs=x,
                                  num_filters=num_filters,
                                  kernel_size=kernel_size,
                                  strides=stride,
                                  activation=activation,
                                  batch_normalization=True,
                                  conv_first=True)
        return x

    def __shortcut(self, x, residual):
        '''
        http://pynote.hatenablog.com/entry/keras-resnet-implementation
        shortcut connection を作成する。
        '''
        x_shape = K.int_shape(x)
        residual_shape = K.int_shape(residual)

        if x_shape == residual_shape:
            # x と residual の形状が同じ場合、なにもしない。
            shortcut = x
        else:
            # x と residual の形状が異なる場合、線形変換を行い、形状を一致させる。
            stride_w = int(round(x_shape[1] / residual_shape[1]))
            stride_h = int(round(x_shape[2] / residual_shape[2]))

            shortcut = Conv2D(filters=residual_shape[3],
                              kernel_size=(1, 1),
                              strides=(stride_w, stride_h),
                              kernel_initializer='he_normal',
                              kernel_regularizer=l2(1.e-4))(x)
        return Add()([shortcut, residual])

    def resnet_ver1(self, input_shape, other_input_shape, num_classes):
        FIRST_NUM_FILTER = 48
        FRIST_STRIDE = 2
        
        NUM_RES_BLOCK = [2, 2, 2]
        FIRST_BLOCK_STRIDES = [2, 2, 2]
        NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*8]

        # input
        image_inputs = Input(shape=input_shape)

        # first layer
        x = self.__resnet_layer(inputs=image_inputs,
                              num_filters=FIRST_NUM_FILTER,
                              kernel_size=3,
                              strides=FRIST_STRIDE,
                              activation='relu',
                              batch_normalization=True,
                              conv_first=True)

        # stacked layer
        for istack in range(len(NUM_RES_BLOCK)):
            # res block
            y = self.__resblock_ver1(input=x, 
                                   num_block=NUM_RES_BLOCK[istack], 
                                   num_filters=NUM_FILTERS[istack], 
                                   kernel_size=3, 
                                   first_block_stride=FIRST_BLOCK_STRIDES[istack])
            # shortcut
            x = self.__shortcut(x, y)

        # to last layer
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = GlobalAveragePooling2D()(x)
        x_shape = K.int_shape(x)

        # other inputs
        if other_input_shape is None:
            z_shape = [0, 0]
        else:
            other_inputs = Input(shape=other_input_shape)
            z = other_inputs
            z = BatchNormalization()(z)
            if len(K.int_shape(z)) > 2:
                z = Flatten()(z)
            z_shape = K.int_shape(z)
            # concatenate
            x = Concatenate()([x, z])

        # fully conection
        #x = Dense(x_shape[1] + z_shape[1],
        #          activation='linear',
        #          kernel_initializer='he_normal')(x)
        #x = BatchNormalization()(x)
        #x = Activation('relu')(x)
        #x = LeakyReLU()(x)
        
        # classification
        outputs = Dense(num_classes,
                        activation='softmax',
                        kernel_initializer='he_normal')(x)

        # Instantiate model.
        if other_input_shape is None:
            model = Model(inputs=image_inputs, outputs=outputs)
        else:
            model = Model(inputs=[image_inputs, other_inputs], outputs=outputs)

        return model

    def resnet_ver2(self, input_shape, other_input_shape, num_classes):
        FIRST_NUM_FILTER = 48
        FRIST_STRIDE = 2
        
        NUM_RES_BLOCK = [6, 8, 6]
        FIRST_BLOCK_STRIDES = [2, 2, 2]
        NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*8]

        #NUM_RES_BLOCK = [2, 2, 
        #                 2, 2, 
        #                 2, 2]
        #FIRST_BLOCK_STRIDES = [1, 2, 
        #                       1, 2, 
        #                       1, 2]
        #NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*2, 
        #               FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*4, 
        #               FIRST_NUM_FILTER*8, FIRST_NUM_FILTER*8]

        # input
        image_inputs = Input(shape=input_shape)

        # first layer
        x = self.__resnet_layer(inputs=image_inputs,
                              num_filters=FIRST_NUM_FILTER,
                              kernel_size=3,
                              strides=FRIST_STRIDE,
                              activation='relu',
                              batch_normalization=True,
                              conv_first=True)

        # stacked layer
        for istack in range(len(NUM_RES_BLOCK)):
            # res block
            y = self.__resblock_ver1(input=x, 
                                   num_block=NUM_RES_BLOCK[istack], 
                                   num_filters=NUM_FILTERS[istack], 
                                   kernel_size=3, 
                                   first_block_stride=FIRST_BLOCK_STRIDES[istack])
            # shortcut
            x = self.__shortcut(x, y)

        # to last layer
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = GlobalAveragePooling2D()(x)
        x_shape = K.int_shape(x)

        # other inputs
        if other_input_shape is None:
            z_shape = [0, 0]
        else:
            other_inputs = Input(shape=other_input_shape)
            z = other_inputs
            z = BatchNormalization()(z)
            if len(K.int_shape(z)) > 2:
                z = Flatten()(z)
            z_shape = K.int_shape(z)
            # concatenate
            x = Concatenate()([x, z])

        # fully conection
        #x = Dense(x_shape[1] + z_shape[1],
        #          activation='linear',
        #          kernel_initializer='he_normal')(x)
        #x = BatchNormalization()(x)
        #x = Activation('relu')(x)
        #x = LeakyReLU()(x)
        
        # classification
        outputs = Dense(num_classes,
                        activation='softmax',
                        kernel_initializer='he_normal')(x)

        # Instantiate model.
        if other_input_shape is None:
            model = Model(inputs=image_inputs, outputs=outputs)
        else:
            model = Model(inputs=[image_inputs, other_inputs], outputs=outputs)

        return model

    def resnet_ver3(self, input_shape, other_input_shape, num_classes):
        FIRST_NUM_FILTER = 48
        FRIST_STRIDE = 2
        
        NUM_RES_BLOCK = [6, 8, 6]
        FIRST_BLOCK_STRIDES = [2, 2, 2]
        NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*8]

        #NUM_RES_BLOCK = [2, 2, 
        #                 2, 2, 
        #                 2, 2]
        #FIRST_BLOCK_STRIDES = [1, 2, 
        #                       1, 2, 
        #                       1, 2]
        #NUM_FILTERS = [FIRST_NUM_FILTER*2, FIRST_NUM_FILTER*2, 
        #               FIRST_NUM_FILTER*4, FIRST_NUM_FILTER*4, 
        #               FIRST_NUM_FILTER*8, FIRST_NUM_FILTER*8]

        # input
        image_inputs = Input(shape=input_shape)

        # first layer
        x = self.__resnet_layer(inputs=image_inputs,
                              num_filters=FIRST_NUM_FILTER,
                              kernel_size=3,
                              strides=FRIST_STRIDE,
                              activation='relu',
                              batch_normalization=True,
                              conv_first=True)

        # stacked layer
        for istack in range(len(NUM_RES_BLOCK)):
            # res block
            y = self.__resblock_ver1(input=x, 
                                   num_block=NUM_RES_BLOCK[istack], 
                                   num_filters=NUM_FILTERS[istack], 
                                   kernel_size=3, 
                                   first_block_stride=FIRST_BLOCK_STRIDES[istack])
            # shortcut
            x = self.__shortcut(x, y)

        # to last layer
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = GlobalAveragePooling2D()(x)
        x_shape = K.int_shape(x)

        # other inputs
        if other_input_shape is None:
            z_shape = [0, 0]
        else:
            other_inputs = Input(shape=other_input_shape)
            z = other_inputs
            z = BatchNormalization()(z)
            if len(K.int_shape(z)) > 2:
                z = Flatten()(z)
            z_shape = K.int_shape(z)
            # concatenate
            x = Concatenate()([x, z])

        # fully conection
        #x = Dense(x_shape[1] + z_shape[1],
        #          activation='linear',
        #          kernel_initializer='he_normal')(x)
        #x = BatchNormalization()(x)
        #x = Activation('relu')(x)
        #x = LeakyReLU()(x)
        
        # classification
        outputs = Dense(num_classes,
                        activation='softmax',
                        kernel_initializer='he_normal')(x)

        # Instantiate model.
        if other_input_shape is None:
            model = Model(inputs=image_inputs, outputs=outputs)
        else:
            model = Model(inputs=[image_inputs, other_inputs], outputs=outputs)

        return model


    def __class_balanced_focal_loss(self, y_true, y_pred):
        """
        https://arxiv.org/abs/1901.05555
        https://qiita.com/tancoro/items/c58cbb33ee1b5971ee3b

        loss = weight * local * base_loss
            where weight = (1 - beta)/(1 - beta^n),
                  focal = (1 - p)^gamma,
                  base_loss: calagorical crossentropy = - p_true * log(p),
        """

        epsilon = 1e-07

        # weight
        if self.CLASS_BALANCE_LOSS_EFFECTIVE_BETA is not None:
            # weight = (1 - beta)/(1 - beta^n)
            # shape = (1, num_y)
            beta = self.CLASS_BALANCE_LOSS_EFFECTIVE_BETA
            
            #label_num = K.sum(y_true, axis=0)
            label_num = self.TRUE_EACH_LABEL_NUM
            
            beta_pow_n = tf.math.pow(beta, label_num)
            weight = (1 - beta) / (1 - beta_pow_n + epsilon)
            weight = weight[tf.newaxis,:]
        else:
            weight = 1.0

        # focal
        if self.FOCAL_LOSS_GAMMA is not None:
            # focal = (1 - p)^gamma
            # shape = (num_sample, num_y)
            gamma = self.FOCAL_LOSS_GAMMA
            focal = K.pow(1 - y_pred + 1e-07, gamma)
        else:
            focal = 1.0

        # calagorical crossentropy
        # shape = (num_sample, num_y)
        base_loss = - y_true * K.log(y_pred + epsilon)

        # loss
        # shape = (num_sample)
        loss = tf.reduce_sum(weight * focal * base_loss, axis=1)

        return loss

    def save_model(self, save_file, only_model_plot=False):
        """
        save model
        """
        # make dir
        save_dir = os.path.dirname(save_file)
        if not os.path.isdir(save_dir):
            os.makedirs(save_dir)

        # visualize
        plot_model(self.model, to_file=os.path.join(save_dir, 'model_structure.png'), show_shapes=True, show_layer_names=False)

        if not only_model_plot:
            # save model
            self.model.save(save_file)
            print('Saved trained model at %s ' % save_file)

        return

    def load_model(self, model_file):
        """
        load model .h5 file
        """
        self.model = load_model(model_file)
        return

    def predict(self, xs, soft=False):
        oups = self.model.predict(xs)
        if not soft:
            # output number
            oups = np.argmax(oups, axis=1)

        return oups

    def predict_tta(self, images, tta_func, other_inputs=None, soft=False, need_print=False):
        """
        Args:
            tta_func:  tta_func(images): return augmented images set. image set is [aug image1, ..., aug imageN].
        """
        if need_print:
            print('tta augment image')
        auged_imgs_set = tta_func(images, other_inputs)
        aug_num = len(auged_imgs_set)

        for iaug, auged_imgs in enumerate(auged_imgs_set):
            if need_print:
                print('tta set no. {0}'.format(iaug))
            if iaug == 0:
                oups = self.model.predict(auged_imgs)
            else:
                oups = oups + self.model.predict(auged_imgs)

        oups = oups / aug_num

        if not soft:
            # output number
            oups = np.argmax(oups, axis=1)
        
        return oups
